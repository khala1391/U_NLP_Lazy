{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary\n",
    "- NLTK: for text processing\n",
    "  - feature\n",
    "    - comprehensive NLP library\n",
    "    - text processing tool (tokenizae, stemming, lemmatize, parsing, syntactic tree)\n",
    "  - application\n",
    "    - linguistic analysis\n",
    "    - tokenization\n",
    "    - stemming\n",
    "    - syntactic parsing\n",
    "- SKlearn: for modeling\n",
    "  - feature\n",
    "    - tool for ML and pipeline (Pipeline, GridSearchCV)\n",
    "    - basic text processing tool (CountVectorzer, TfidVectorizer)\n",
    "  - application\n",
    "    - text classification\n",
    "    - clustering\n",
    "    - task with integrated ML into text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()   # popup for selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('omw-1.4')                   # Word senses, synonyms, translations (used in lemmatization with POS)\n",
    "# nltk.download('punkt')                     # For tokenization\n",
    "# nltk.download('wordnet')                   # For lemmatization\n",
    "# nltk.download('stopwords')                 # For stopword removal\n",
    "# nltk.download('averaged_perceptron_tagger')# For POS tagging\n",
    "# nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 'bbc_text_cls.csv' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/shivamkushwaha/bbc-full-text-document-classification\n",
    "!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_sklearn_example.ipynb\n",
      "01_Stem_and_Lemmatize.ipynb\n",
      "02_countvect.ipynb\n",
      "03_TFIDF_recommender.ipynb\n",
      "05_WordEmbedding.ipynb\n",
      "GoogleNews-vectors-negative300.bin\n",
      "GoogleNews-vectors-negative300.bin.gz\n",
      "bbc_text_cls.csv\n",
      "tmdb_5000_movies.csv\n",
      "tmdb_5000_movies.csv.1\n",
      "txt_nlp.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc_text_cls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "labels",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b885f9e2-aeb2-48a0-a455-3a5b434c0d7d",
       "rows": [
        [
         "0",
         "Ad sales boost Time Warner profit\n\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n\nTime Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n\nTimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.",
         "business"
        ],
        [
         "1",
         "Dollar gains on Greenspan speech\n\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\n\nAnd Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\n\nWorries about the deficit concerns about China do, however, remain. China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing's policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve's decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US's yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.",
         "business"
        ],
        [
         "2",
         "Yukos unit buyer faces loan claim\n\nThe owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (£479m) loan.\n\nState-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets. Rosneft already faces a similar $540m repayment demand from foreign banks. Legal experts said Rosneft's purchase of Yugansk would include such obligations. \"The pledged assets are with Rosneft, so it will have to pay real money to the creditors to avoid seizure of Yugansk assets,\" said Moscow-based US lawyer Jamie Firestone, who is not connected to the case. Menatep Group's managing director Tim Osborne told the Reuters news agency: \"If they default, we will fight them where the rule of law exists under the international arbitration clauses of the credit.\"\n\nRosneft officials were unavailable for comment. But the company has said it intends to take action against Menatep to recover some of the tax claims and debts owed by Yugansk. Yukos had filed for bankruptcy protection in a US court in an attempt to prevent the forced sale of its main production arm. The sale went ahead in December and Yugansk was sold to a little-known shell company which in turn was bought by Rosneft. Yukos claims its downfall was punishment for the political ambitions of its founder Mikhail Khodorkovsky and has vowed to sue any participant in the sale.",
         "business"
        ],
        [
         "3",
         "High fuel prices hit BA's profits\n\nBritish Airways has blamed high fuel prices for a 40% drop in profits.\n\nReporting its results for the three months to 31 December 2004, the airline made a pre-tax profit of £75m ($141m) compared with £125m a year earlier. Rod Eddington, BA's chief executive, said the results were \"respectable\" in a third quarter when fuel costs rose by £106m or 47.3%. BA's profits were still better than market expectation of £59m, and it expects a rise in full-year revenues.\n\nTo help offset the increased price of aviation fuel, BA last year introduced a fuel surcharge for passengers.\n\nIn October, it increased this from £6 to £10 one-way for all long-haul flights, while the short-haul surcharge was raised from £2.50 to £4 a leg. Yet aviation analyst Mike Powell of Dresdner Kleinwort Wasserstein says BA's estimated annual surcharge revenues - £160m - will still be way short of its additional fuel costs - a predicted extra £250m. Turnover for the quarter was up 4.3% to £1.97bn, further benefiting from a rise in cargo revenue. Looking ahead to its full year results to March 2005, BA warned that yields - average revenues per passenger - were expected to decline as it continues to lower prices in the face of competition from low-cost carriers. However, it said sales would be better than previously forecast. \"For the year to March 2005, the total revenue outlook is slightly better than previous guidance with a 3% to 3.5% improvement anticipated,\" BA chairman Martin Broughton said. BA had previously forecast a 2% to 3% rise in full-year revenue.\n\nIt also reported on Friday that passenger numbers rose 8.1% in January. Aviation analyst Nick Van den Brul of BNP Paribas described BA's latest quarterly results as \"pretty modest\". \"It is quite good on the revenue side and it shows the impact of fuel surcharges and a positive cargo development, however, operating margins down and cost impact of fuel are very strong,\" he said. Since the 11 September 2001 attacks in the United States, BA has cut 13,000 jobs as part of a major cost-cutting drive. \"Our focus remains on reducing controllable costs and debt whilst continuing to invest in our products,\" Mr Eddington said. \"For example, we have taken delivery of six Airbus A321 aircraft and next month we will start further improvements to our Club World flat beds.\" BA's shares closed up four pence at 274.5 pence.",
         "business"
        ],
        [
         "4",
         "Pernod takeover talk lifts Domecq\n\nShares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.\n\nReports in the Wall Street Journal and the Financial Times suggested that the French spirits firm is considering a bid, but has yet to contact its target. Allied Domecq shares in London rose 4% by 1200 GMT, while Pernod shares in Paris slipped 1.2%. Pernod said it was seeking acquisitions but refused to comment on specifics.\n\nPernod's last major purchase was a third of US giant Seagram in 2000, the move which propelled it into the global top three of drinks firms. The other two-thirds of Seagram was bought by market leader Diageo. In terms of market value, Pernod - at 7.5bn euros ($9.7bn) - is about 9% smaller than Allied Domecq, which has a capitalisation of £5.7bn ($10.7bn; 8.2bn euros). Last year Pernod tried to buy Glenmorangie, one of Scotland's premier whisky firms, but lost out to luxury goods firm LVMH. Pernod is home to brands including Chivas Regal Scotch whisky, Havana Club rum and Jacob's Creek wine. Allied Domecq's big names include Malibu rum, Courvoisier brandy, Stolichnaya vodka and Ballantine's whisky - as well as snack food chains such as Dunkin' Donuts and Baskin-Robbins ice cream. The WSJ said that the two were ripe for consolidation, having each dealt with problematic parts of their portfolio. Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.",
         "business"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df['text']\n",
    "labels = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels.hist(figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling w/o STOP WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, inputs_test, Ytrain, Ytest = train_test_split(\n",
    "    inputs, labels, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix\n",
    "- spicy sparse matrix\n",
    "- dense matrix (normal numpy array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **sparse matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 337411 stored elements and shape (1668, 26287)>\n",
      "  Coords\tValues\n",
      "  (0, 25718)\t3\n",
      "  (0, 21493)\t3\n",
      "  (0, 12374)\t1\n",
      "  (0, 23988)\t3\n",
      "  (0, 5212)\t1\n",
      "  (0, 21184)\t1\n",
      "  (0, 11348)\t2\n",
      "  (0, 7951)\t1\n",
      "  (0, 22558)\t1\n",
      "  (0, 24876)\t2\n",
      "  (0, 23660)\t37\n",
      "  (0, 16720)\t22\n",
      "  (0, 16742)\t1\n",
      "  (0, 7766)\t2\n",
      "  (0, 9546)\t1\n",
      "  (0, 5674)\t1\n",
      "  (0, 4372)\t4\n",
      "  (0, 22926)\t1\n",
      "  (0, 22005)\t1\n",
      "  (0, 10798)\t6\n",
      "  (0, 7101)\t3\n",
      "  (0, 11106)\t3\n",
      "  (0, 7872)\t1\n",
      "  (0, 16588)\t2\n",
      "  (0, 3282)\t2\n",
      "  :\t:\n",
      "  (1667, 19170)\t1\n",
      "  (1667, 2264)\t1\n",
      "  (1667, 3035)\t1\n",
      "  (1667, 6338)\t1\n",
      "  (1667, 15643)\t1\n",
      "  (1667, 21196)\t1\n",
      "  (1667, 4036)\t1\n",
      "  (1667, 7300)\t1\n",
      "  (1667, 5939)\t1\n",
      "  (1667, 22654)\t1\n",
      "  (1667, 6710)\t1\n",
      "  (1667, 12566)\t1\n",
      "  (1667, 3071)\t1\n",
      "  (1667, 7942)\t1\n",
      "  (1667, 16419)\t1\n",
      "  (1667, 24351)\t1\n",
      "  (1667, 5026)\t1\n",
      "  (1667, 3352)\t1\n",
      "  (1667, 9941)\t1\n",
      "  (1667, 5583)\t1\n",
      "  (1667, 16385)\t1\n",
      "  (1667, 3884)\t1\n",
      "  (1667, 17331)\t1\n",
      "  (1667, 10661)\t1\n",
      "  (1667, 9618)\t1\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1042, 23660, 205), (11, 23660, 190), (1639, 23660, 169), (417, 23660, 145), (593, 23660, 133), (328, 23660, 131), (1647, 23660, 112), (11, 23902, 106), (1138, 23660, 98), (1647, 23902, 93)]\n"
     ]
    }
   ],
   "source": [
    "coo = Xtrain.tocoo()\n",
    "# sort by data values\n",
    "sorted_entries = sorted(zip(coo.row, coo.col, coo.data), key=lambda x: x[2], reverse=True)\n",
    "print(sorted_entries[:10]) \n",
    "\n",
    "# (row_index, column_index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary: word -> column index\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "# To get index -> word, invert the dict\n",
    "inv_vocab = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "# Given a column index, e.g. 23660 (in your case)\n",
    "col_index = 23902\n",
    "\n",
    "# Get the word, if present:\n",
    "word = inv_vocab.get(col_index, \"UNKNOWN\")\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Xtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **dense matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1668, 26287)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dense matrix (for viewing only)\n",
    "display(Xtrain.toarray().shape)\n",
    "Xtrain.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **dense matrix with selected %sparsity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.56063582 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.37238016\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18793431 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.98973336 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.98755036]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define shape and sparsity\n",
    "shape = (10, 10)\n",
    "sparsity_percent = 5\n",
    "num_elements = shape[0] * shape[1]\n",
    "num_nonzero = int((sparsity_percent / 100) * num_elements)\n",
    "\n",
    "# Initialize all zeros\n",
    "dense_matrix = np.zeros(shape)\n",
    "\n",
    "# Randomly choose indices to set non-zero values\n",
    "nonzero_indices = np.random.choice(num_elements, num_nonzero, replace=False)\n",
    "\n",
    "# Fill selected positions with random values\n",
    "for index in nonzero_indices:\n",
    "    row, col = divmod(index, shape[1])\n",
    "    dense_matrix[row, col] = np.random.rand()\n",
    "\n",
    "print(dense_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **convert dense_matrix to sparse_matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 5 stored elements and shape (10, 10)>\n",
      "  Coords\tValues\n",
      "  (0, 4)\t0.5606358193812049\n",
      "  (2, 5)\t0.3723801639419534\n",
      "  (3, 8)\t0.18793430804233924\n",
      "  (6, 3)\t0.9897333645784311\n",
      "  (7, 9)\t0.9875503568322697\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert to CSR format\n",
    "sparse_matrix = csr_matrix(dense_matrix)\n",
    "\n",
    "print(sparse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **convert sparse_matrix to dense_matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.56063582 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.37238016\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18793431 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.98973336 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.98755036]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Dense to Array\n",
    "dense_matrix = sparse_matrix.todense()\n",
    "print(dense_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**back to course**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337411"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Xtrain != 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**% sparsity** is  % of non-zero\n",
    "- definition\n",
    "  - Sparsity = % of zero elements = 100 - density\n",
    "  - Density = % of nonzero elements (what you calculated).\n",
    "- example\n",
    "  - If your result is small (e.g., 2%), the matrix is very sparse (98% zeros).\n",
    "  - If the result is large (e.g., 90%), the matrix is dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007695239935415004"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what percentage of values are non-zero?\n",
    "# (Xtrain != 0).sum() / np.prod(Xtrain.shape)*100\n",
    "(Xtrain != 0).sum() / np.prod(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9922062350119905\n",
      "test score: 0.9712746858168761\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_wo_stop_word = Xtrain.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with STOP WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9928057553956835\n",
      "test score: 0.9766606822262118\n"
     ]
    }
   ],
   "source": [
    "# with stopwords\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "  if treebank_tag.startswith('J'):\n",
    "    return wordnet.ADJ\n",
    "  elif treebank_tag.startswith('V'):\n",
    "    return wordnet.VERB\n",
    "  elif treebank_tag.startswith('N'):\n",
    "    return wordnet.NOUN\n",
    "  elif treebank_tag.startswith('R'):\n",
    "    return wordnet.ADV\n",
    "  else:\n",
    "    return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "  def __init__(self):\n",
    "    self.wnl = WordNetLemmatizer()\n",
    "  def __call__(self, doc):\n",
    "    tokens = word_tokenize(doc)\n",
    "    words_and_tags = nltk.pos_tag(tokens)\n",
    "    return [self.wnl.lemmatize(word, pos=get_wordnet_pos(tag)) \\\n",
    "            for word, tag in words_and_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khala\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9922062350119905\n",
      "test score: 0.9676840215439856\n"
     ]
    }
   ],
   "source": [
    "# with lemmatization\n",
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer())\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemTokenizer:\n",
    "  def __init__(self):\n",
    "    self.porter = PorterStemmer()\n",
    "  def __call__(self, doc):\n",
    "    tokens = word_tokenize(doc)\n",
    "    return [self.porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khala\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9892086330935251\n",
      "test score: 0.9694793536804309\n"
     ]
    }
   ],
   "source": [
    "# with stemming\n",
    "vectorizer = CountVectorizer(tokenizer=StemTokenizer())\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(s):\n",
    "  return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khala\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9952038369304557\n",
      "test score: 0.9712746858168761\n"
     ]
    }
   ],
   "source": [
    "# string split tokenizer\n",
    "vectorizer = CountVectorizer(tokenizer=simple_tokenizer)\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the vector dimensionality in each case?\n",
    "# Compare them and consider why they are larger / smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain.shape w/o stopword: (1668, 26287) \n"
     ]
    }
   ],
   "source": [
    "# without stopwords\n",
    "print(f'Xtrain.shape w/o stopword: {Xtrain_wo_stop_word.shape} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain.shape with stopword: (1668, 25995) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khala\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain.shape with lemmatization: (1668, 25894) \n",
      "Xtrain.shape with stemming: (1668, 22714) \n",
      "Xtrain.shape with simple tokenizer: (1668, 52144) \n"
     ]
    }
   ],
   "source": [
    "# with stopwords\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "print(f'Xtrain.shape with stopword: {Xtrain.shape} ')\n",
    "\n",
    "# with lemmatization\n",
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer())\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "print(f'Xtrain.shape with lemmatization: {Xtrain.shape} ')\n",
    "\n",
    "# with stemming\n",
    "vectorizer = CountVectorizer(tokenizer=StemTokenizer())\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "print(f'Xtrain.shape with stemming: {Xtrain.shape} ')\n",
    "\n",
    "# string split tokenizer\n",
    "vectorizer = CountVectorizer(tokenizer=simple_tokenizer)\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "print(f'Xtrain.shape with simple tokenizer: {Xtrain.shape} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- w/o stop word\n",
    "  - train score: 0.9922062350119905\n",
    "  - test score: 0.9712746858168761\n",
    "- w stop word\n",
    "  - train score: 0.9928057553956835\n",
    "  - test score: 0.9766606822262118\n",
    "- lemmatization\n",
    "  - train score: 0.9922062350119905\n",
    "  - test score: 0.9676840215439856\n",
    "- stemming\n",
    "  - train score: 0.9892086330935251\n",
    "  - test score: 0.9694793536804309\n",
    "- tokenizer\n",
    "  - train score: 0.9952038369304557\n",
    "  - test score: 0.9712746858168761"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
