{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9bf3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43c0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = {} # start of a phrase\n",
    "first_order = {} # second word only\n",
    "second_order = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06d385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb23ae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 'robert_frost.txt' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8edcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dict(d, k, v):\n",
    "  if k not in d:\n",
    "    d[k] = []\n",
    "  d[k].append(v)\n",
    "\n",
    "# [cat, cat, dog, dog, dog, dog, dog, mouse, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c8c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('robert_frost.txt'):\n",
    "  tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "\n",
    "  T = len(tokens)\n",
    "  for i in range(T):\n",
    "    t = tokens[i]\n",
    "    if i == 0:\n",
    "      # measure the distribution of the first word\n",
    "      initial[t] = initial.get(t, 0.) + 1\n",
    "    else:\n",
    "      t_1 = tokens[i-1]\n",
    "      if i == T - 1:\n",
    "        # measure probability of ending the line\n",
    "        add2dict(second_order, (t_1, t), 'END')\n",
    "      if i == 1:\n",
    "        # measure distribution of second word\n",
    "        # given only first word\n",
    "        add2dict(first_order, t_1, t)\n",
    "      else:\n",
    "        t_2 = tokens[i-2]\n",
    "        add2dict(second_order, (t_2, t_1), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76a655ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the distributions\n",
    "initial_total = sum(initial.values())\n",
    "for t, c in initial.items():\n",
    "    initial[t] = c / initial_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b39d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert [cat, cat, cat, dog, dog, dog, dog, mouse, ...]\n",
    "# into {cat: 0.5, dog: 0.4, mouse: 0.1}\n",
    "\n",
    "def list2pdict(ts):\n",
    "  # turn each list of possibilities into a dictionary of probabilities\n",
    "  d = {}\n",
    "  n = len(ts)\n",
    "  for t in ts:\n",
    "    d[t] = d.get(t, 0.) + 1\n",
    "  for t, c in d.items():\n",
    "    d[t] = c / n\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d64c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_1, ts in first_order.items():\n",
    "  # replace list with dictionary of probabilities\n",
    "  first_order[t_1] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc76a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ts in second_order.items():\n",
    "  second_order[k] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f83fd8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(d):\n",
    "  # print \"d:\", d\n",
    "  p0 = np.random.random()\n",
    "  # print \"p0:\", p0\n",
    "  cumulative = 0\n",
    "  for t, p in d.items():\n",
    "    cumulative += p\n",
    "    if p0 < cumulative:\n",
    "      return t\n",
    "  assert(False) # should never get here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf5db825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "  for i in range(4): # generate 4 lines\n",
    "    sentence = []\n",
    "\n",
    "    # initial word\n",
    "    w0 = sample_word(initial)\n",
    "    sentence.append(w0)\n",
    "\n",
    "    # sample second word\n",
    "    w1 = sample_word(first_order[w0])\n",
    "    sentence.append(w1)\n",
    "\n",
    "    # second-order transitions until END\n",
    "    while True:\n",
    "      w2 = sample_word(second_order[(w0, w1)])\n",
    "      if w2 == 'END':\n",
    "        break\n",
    "      sentence.append(w2)\n",
    "      w0 = w1\n",
    "      w1 = w2\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc699572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i went to bed alone and left me\n",
      "might just as empty\n",
      "but it isnt as if and thats not all the money goes so fast\n",
      "you couldnt call it living for it aint\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "718ea0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "#\n",
    "# Determine the vocabulary size (V)\n",
    "# We know that pi has shape V, A1 has shape V x V, and A2 has shape V x V x V\n",
    "#\n",
    "# In comparison, how many values are stored in our dictionaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5df663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2:\n",
    "# We can skip the step where we accumulate all the possible next words in a list\n",
    "# E.g. [cat, cat, dog, dog, dog, ...]\n",
    "#\n",
    "# Instead, like we do with the initial state distribution, create the dictionary\n",
    "# of counts directly as you loop through the data.\n",
    "#\n",
    "# You'll no longer need list2pdict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
